{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18e409a3-f625-4d26-89ba-866eceb7c0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T10:23:06.355023Z",
     "iopub.status.busy": "2024-05-09T10:23:06.355023Z",
     "iopub.status.idle": "2024-05-09T10:23:42.402668Z",
     "shell.execute_reply": "2024-05-09T10:23:42.392838Z",
     "shell.execute_reply.started": "2024-05-09T10:23:06.355023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt flow service...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-09 15:53:35,764][promptflow][WARNING] - The starting prompt flow process did not finish within the timeout period. Kindly reminder: If you have previously upgraded the prompt flow package , please double-confirm that you have run '\u001b[1mpf service stop\u001b[0m' to stop the prompt flowservice before proceeding with the upgrade. Otherwise, you may encounter unexpected environmental issues or inconsistencies between the version of running prompt flow service and the local prompt flow version. Alternatively, you can use the '\u001b[1mpf upgrade\u001b[0m' command to proceed with the upgrade process for the prompt flow package.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "Alternatively, if no requests are made within 1 hours, it will automatically stop.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI, OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('azure.env')\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from promptflow.tracing import start_trace\n",
    "\n",
    "# instrument OpenAI\n",
    "start_trace()\n",
    "\n",
    "client = AzureOpenAI(api_version=\"2024-03-01-preview\", \n",
    "                     azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                     azure_deployment='gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df00f9a-dd11-4d8c-aa27-90a31489846d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T10:12:36.707678Z",
     "iopub.status.busy": "2024-05-09T10:12:36.707348Z",
     "iopub.status.idle": "2024-05-09T10:12:36.742510Z",
     "shell.execute_reply": "2024-05-09T10:12:36.735526Z",
     "shell.execute_reply.started": "2024-05-09T10:12:36.707678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python': <bound method PythonREPL.run of <__main__.PythonREPL object at 0x000002751CD71D90>>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.tools import PythonAstREPLTool\n",
    "from colorama import Fore\n",
    "import re\n",
    "\n",
    "class PythonREPL:\n",
    "    def __init__(self):\n",
    "        self.local_vars = {}\n",
    "        self.python_tool = PythonAstREPLTool()\n",
    "    def run(self, code: str) -> str:\n",
    "        code = extract_code_from_block(code)\n",
    "        output = str(self.python_tool.run(code))\n",
    "        if output == \"\":\n",
    "            return \"Your code is executed successfully\"\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "\n",
    "def get_tool_info(tool_name):\n",
    "    tools = {\n",
    "        \"python\": {\"type\": \"tool\", \n",
    "                   \"name\": \"python\", \n",
    "                   \"use\": \"Use this to execute python code. Display your results using the print function.\", \n",
    "                   \"input\": \"Input should be a valid python code. Ensure proper indentation\", \n",
    "                   \"function\": python_repl.run},\n",
    "        }\n",
    "    return tools[tool_name]\n",
    "\n",
    "\n",
    "\n",
    "tools = []\n",
    "value_dict = {}\n",
    "tools_description = \"\\n\\nYou can use the following actions:\\n\\n\" \n",
    "choice = 'python'\n",
    "tools.append(choice)\n",
    "tool_info = get_tool_info(choice)\n",
    "tools_description = tools_description + \"Action Name: \" + tool_info[\"name\"] + \"\\nWhen To Use: \" + tool_info[\"use\"] + \"\\nInput: \" + tool_info[\"input\"]\n",
    "tools_description = tools_description + \"\\n\\n\"\n",
    "value_dict[choice] = tool_info[\"function\"]\n",
    "value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "908225b6-b42a-401c-9ea2-1307659e8d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T10:12:38.595988Z",
     "iopub.status.busy": "2024-05-09T10:12:38.595377Z",
     "iopub.status.idle": "2024-05-09T10:12:38.618069Z",
     "shell.execute_reply": "2024-05-09T10:12:38.616435Z",
     "shell.execute_reply.started": "2024-05-09T10:12:38.595988Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(content, instruction):\n",
    "    content = content.replace('<<instruction>>', instruction)\n",
    "    count = 0\n",
    "    while(True):\n",
    "        count = count + 1\n",
    "        if count > 5:\n",
    "            raise ValueError(\"Too many steps\")\n",
    "        #print(Fore.BLUE + content)\n",
    "        output = llm(content)\n",
    "        output = output.replace(\"\\nObservation:\", \"\")\n",
    "        print(Fore.MAGENTA + output)\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nInput\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, output, re.DOTALL)\n",
    "\n",
    "        if \"Final Answer:\" in output and not match:\n",
    "            break\n",
    "            print(output.split(\"Final Answer:\")[1])\n",
    "\n",
    "        if \"Step\" not in output:\n",
    "            print(Fore.YELLOW + \"The model didnt output a step.\")\n",
    "            output = \"Please follow the format Step/Reason/Action/Input/Observation\"\n",
    "            content = content + \"\\n\" + output\n",
    "            continue\n",
    "\n",
    "        if \"Reason\" not in output:\n",
    "            print(Fore.YELLOW + \"The model didnt output a reason.\")\n",
    "            output = \"Please follow the format Step/Reason/Action/Input/Observation\"\n",
    "            messages = content + \"\\n\" + output\n",
    "            continue\n",
    "\n",
    "        if output.count(\"Input\") > 1:\n",
    "            print(Fore.YELLOW + \"The model went crazy.\")\n",
    "            output = \"Please go one step at a time.\"\n",
    "            content = content + \"\\n\" + output\n",
    "            continue\n",
    "\n",
    "        if not match:\n",
    "            print(Fore.RED + \"The model was sidetracked.\")\n",
    "            output = \"You are not following the format. Please follow the given format.\"\n",
    "            messages = [{\"role\": \"user\", \"content\": content + \"\\n\" + output}]\n",
    "            continue\n",
    "\n",
    "\n",
    "        action = match.group(1).strip().lower()\n",
    "        if action not in tools:\n",
    "            output = f\"Invalid Action. Your action should be one of {tools}.\"\n",
    "            print(Fore.YELLOW + \"The agent forgot his tools.\" + output) \n",
    "            content = content + \"\\n\" + output\n",
    "            continue\n",
    "\n",
    "        action_input = match.group(2)\n",
    "        match = re.search(r\"Step (\\d+): (.*)\", output)\n",
    "        step_number = int(match.group(1)) + 1\n",
    "        observation = value_dict[action](action_input)\n",
    "        print(Fore.GREEN + \"\\nObservation: \" + str(observation))\n",
    "        output = output + \"\\nObservation: \" + str(observation)\n",
    "        content = content + \"\\n\" + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ae18f61-96dd-4ade-a336-0fab54641460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T10:12:39.438884Z",
     "iopub.status.busy": "2024-05-09T10:12:39.438884Z",
     "iopub.status.idle": "2024-05-09T10:12:39.459456Z",
     "shell.execute_reply": "2024-05-09T10:12:39.459456Z",
     "shell.execute_reply.started": "2024-05-09T10:12:39.438884Z"
    }
   },
   "outputs": [],
   "source": [
    "content = \"\"\"You can use the following actions:\n",
    "\n",
    "Action Name: python\n",
    "When To Use: When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution\n",
    "seconds.\n",
    "Input: Input should be a valid python code. Ensure proper indentation\n",
    "\n",
    "Acomplish the task in steps. If you get error in previous step fix it in the current step. Use the following format:\n",
    "\n",
    "Step 1: The first step\n",
    "Reason: Reason for taking this step\n",
    "Action: the action to take, should be one of ['python'].\n",
    "Input: the input to the action\n",
    "Observation: the result of the action\n",
    "\n",
    "Step 2: The second step\n",
    "Reason: Reason for taking this step\n",
    "Action: the action to take, should be one of ['python'].\n",
    "Input: the input to the action \n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Step/Reason/Action/Input/Observation repeats for all steps)\n",
    "\n",
    "Once you have completed all the steps, your final answer should be in the format:\n",
    "Final Answer: I have completed all the steps\n",
    "\n",
    "Begin\n",
    "\n",
    "<<instruction>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d467839-c5d1-4a49-9ad3-d45a5bdbe42b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T10:12:40.095420Z",
     "iopub.status.busy": "2024-05-09T10:12:40.095420Z",
     "iopub.status.idle": "2024-05-09T10:12:40.114166Z",
     "shell.execute_reply": "2024-05-09T10:12:40.114166Z",
     "shell.execute_reply.started": "2024-05-09T10:12:40.095420Z"
    }
   },
   "outputs": [],
   "source": [
    "def llm(user_input):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4-1106-preview',\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': user_input}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        stream=False,\n",
    "        #stream_options={\"include_usage\": True}, # retrieving token usage for stream response\n",
    "    )\n",
    "    return response.choices[0].message.content# a ChatCompletion request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ec084e2-31ca-4f9c-9fb8-82c75e4831f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T10:12:40.999330Z",
     "iopub.status.busy": "2024-05-09T10:12:40.998172Z",
     "iopub.status.idle": "2024-05-09T10:12:41.016196Z",
     "shell.execute_reply": "2024-05-09T10:12:41.016196Z",
     "shell.execute_reply.started": "2024-05-09T10:12:40.999330Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_code_from_block(response):\n",
    "    if '```' not in response:\n",
    "        return response\n",
    "    if '```python' in response:\n",
    "        code_regex = r'```python(.+?)```'\n",
    "    else:\n",
    "        code_regex = r'```(.+?)```'\n",
    "    code_matches = re.findall(code_regex, response, re.DOTALL)\n",
    "    code_matches = [item for item in code_matches]\n",
    "    return  \"\\n\".join(code_matches)\n",
    "\n",
    "def fix_error(code, result):\n",
    "    count = 0\n",
    "    while \"Your code has the following error.\" in result:\n",
    "        error = result.replace(\"Your code has the following error. Please provide the corrected code.\", \"\")\n",
    "        user_input = f\"\"\"Here is the Code and the Error. \n",
    "\n",
    "Code:\n",
    "{code}\n",
    "\n",
    "Error:\n",
    "{error}\n",
    "\n",
    "Fix the given using the following format:\n",
    "\n",
    "Explanation: Explain the error in the code\n",
    "\n",
    "Corrected Code: Put the Corrected Code here\"\"\"\n",
    "        print(Fore.RED + \"Code needs some correction.\\n\" )\n",
    "        code = llm(user_input)\n",
    "        code = code[code.rfind('Corrected Code:') + len(\"Corrected Code:\"):]\n",
    "        code = extract_code_from_block(code)\n",
    "        print(Fore.CYAN + \"Corrected Code.\\n\" + code)\n",
    "        result = python_repl.run(code)\n",
    "        print(Fore.BLUE + \"Result.\\n\" + result)\n",
    "        count += 1\n",
    "        if count > 5:\n",
    "            raise ValueError(\"Too many steps\")\n",
    "    print(Fore.GREEN + \"Code has been corrected.\\n\" + code)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f596db-2c80-4bf7-8d8c-2d42e11e452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(instruction):\n",
    "    return run(content,instruction)\n",
    "command = \"\"\"print the glimpse of iris.csv.\n",
    "Preprocess the data before trainig the model.\n",
    "Train a random forest model to predict the Species column.\n",
    "Save the classification report in result.txt\"\"\"\n",
    "execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868a479-ac10-4fa0-8351-2b33380ed040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
