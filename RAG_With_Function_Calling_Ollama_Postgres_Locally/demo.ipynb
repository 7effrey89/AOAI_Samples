{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286767c6-98dd-44a4-acdb-c76aaa070728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:56:55.867158Z",
     "iopub.status.busy": "2024-08-09T16:56:55.867158Z",
     "iopub.status.idle": "2024-08-09T16:56:55.980604Z",
     "shell.execute_reply": "2024-08-09T16:56:55.978357Z",
     "shell.execute_reply.started": "2024-08-09T16:56:55.867158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('azure.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba525658-6bac-436b-b1ef-f8b7ed98e92e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:56:56.061296Z",
     "iopub.status.busy": "2024-08-09T16:56:56.057486Z",
     "iopub.status.idle": "2024-08-09T16:57:00.148244Z",
     "shell.execute_reply": "2024-08-09T16:57:00.140633Z",
     "shell.execute_reply.started": "2024-08-09T16:56:56.061296Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"llama3.1\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6b9b06-c9b7-4abe-816f-53a5cedebccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:57:35.334580Z",
     "iopub.status.busy": "2024-08-09T16:57:35.334580Z",
     "iopub.status.idle": "2024-08-09T16:57:35.366572Z",
     "shell.execute_reply": "2024-08-09T16:57:35.361554Z",
     "shell.execute_reply.started": "2024-08-09T16:57:35.334580Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"name\": \"search_database\",\n",
    "        \"description\": \"Search PostgreSQL database for relevant products based on user query\",\n",
    "            \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"search_query\": {\n",
    "                \"type\": \"string\",\n",
    "                    \"description\": \"Query string to use for full text search, e.g. 'red shoes'\",\n",
    "                },\n",
    "            \"price_filter\": {\n",
    "                \"type\": \"object\",\n",
    "                    \"description\": \"Filter search results based on price of the product\",\n",
    "                        \"properties\": {\n",
    "                    \"comparison_operator\": {\n",
    "                        \"type\": \"string\",\n",
    "                            \"description\": \"Operator to compare the column value, either '>', '<', '>=', '<=', '='\",  # noqa\n",
    "                    },\n",
    "                    \"value\": {\n",
    "                        \"type\": \"number\",\n",
    "                            \"description\": \"Value to compare against, e.g. 30\",\n",
    "                        },\n",
    "                },\n",
    "            },\n",
    "            \"brand_filter\": {\n",
    "                \"type\": \"object\",\n",
    "                    \"description\": \"Filter search results based on brand of the product\",\n",
    "                        \"properties\": {\n",
    "                    \"comparison_operator\": {\n",
    "                        \"type\": \"string\",\n",
    "                            \"description\": \"Operator to compare the column value, either '=' or '!='\",\n",
    "                        },\n",
    "                    \"value\": {\n",
    "                        \"type\": \"string\",\n",
    "                            \"description\": \"Value to compare against, e.g. AirStrider\",\n",
    "                        },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"search_query\"],\n",
    "        }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa22e69-a07b-4237-8110-30b47501ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llm.bind_tools(tools, function_call={\"name\": \"search_database\"})\n",
    "llm.invoke(\"Best shoe for hiking?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68a61f-0dc8-497d-99ae-21808fe2be2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-09T16:57:45.256844Z",
     "iopub.status.idle": "2024-08-09T16:57:45.256844Z",
     "shell.execute_reply": "2024-08-09T16:57:45.256844Z",
     "shell.execute_reply.started": "2024-08-09T16:57:45.256844Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_deployment=\"text-embedding-ada-002\",\n",
    "    openai_api_version=\"2024-03-01-preview\",\n",
    "    azure_endpoint =os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbaa36ae-efa5-4b13-9598-4aee71574cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:59:19.290782Z",
     "iopub.status.busy": "2024-08-09T16:59:19.289556Z",
     "iopub.status.idle": "2024-08-09T16:59:21.129628Z",
     "shell.execute_reply": "2024-08-09T16:59:21.127291Z",
     "shell.execute_reply.started": "2024-08-09T16:59:19.290782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_QsjsguTvwjzG84N155TMrwAv', 'function': {'arguments': '{\"search_query\":\"hiking shoes\"}', 'name': 'search_database'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_abc28019ad'}, id='run-a5162ab3-887a-4188-8a78-8985152e9c74-0', tool_calls=[{'name': 'search_database', 'args': {'search_query': 'hiking shoes'}, 'id': 'call_QsjsguTvwjzG84N155TMrwAv', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = llm.bind_tools(tools)\n",
    "llm.invoke(\"Best shoe for hiking?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a3e7221-c31c-4f1b-859f-7da2fc93bb54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:58:52.180987Z",
     "iopub.status.busy": "2024-08-09T16:58:52.180987Z",
     "iopub.status.idle": "2024-08-09T16:58:54.394574Z",
     "shell.execute_reply": "2024-08-09T16:58:54.393945Z",
     "shell.execute_reply.started": "2024-08-09T16:58:52.180987Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(api_key = os.environ[\"AZURE_OPENAI_KEY\"],  \n",
    "                      api_version=\"2024-05-01-preview\",\n",
    "                      azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "                      azure_deployment= \"gpt-4o\",\n",
    "                      model=\"gpt-4o\",\n",
    "                      streaming=True)\n",
    "llm = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f736e42-f9aa-42d1-86e8-2dc9e88c0949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:59:31.034096Z",
     "iopub.status.busy": "2024-08-09T16:59:31.034096Z",
     "iopub.status.idle": "2024-08-09T16:59:31.060204Z",
     "shell.execute_reply": "2024-08-09T16:59:31.060204Z",
     "shell.execute_reply.started": "2024-08-09T16:59:31.034096Z"
    }
   },
   "outputs": [],
   "source": [
    "few_shot_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"good options for climbing gear that can be used outside?\"},\n",
    "    {\"role\": \"assistant\", \"tool_calls\": [\n",
    "        {\n",
    "            \"id\": \"call_abc123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"arguments\": \"{\\\"search_query\\\":\\\"climbing gear outside\\\"}\",\n",
    "                \"name\": \"search_database\"\n",
    "            }\n",
    "        }\n",
    "    ]},\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": \"call_abc123\",\n",
    "        \"content\": \"Search results for climbing gear that can be used outside: ...\"\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"are there any shoes less than $50?\"},\n",
    "    {\"role\": \"assistant\", \"tool_calls\": [\n",
    "        {\n",
    "            \"id\": \"call_abc456\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"arguments\": \"{\\\"search_query\\\":\\\"shoes\\\",\\\"price_filter\\\":{\\\"comparison_operator\\\":\\\"<\\\",\\\"value\\\":50}}\",\n",
    "                \"name\": \"search_database\"\n",
    "            }\n",
    "        }\n",
    "    ]},\n",
    "    {\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": \"call_abc456\",\n",
    "        \"content\": \"Search results for shoes cheaper than 50: ...\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658df44e-fa22-48bd-9a65-ac32667fcd1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:59:34.775393Z",
     "iopub.status.busy": "2024-08-09T16:59:34.775393Z",
     "iopub.status.idle": "2024-08-09T16:59:36.893777Z",
     "shell.execute_reply": "2024-08-09T16:59:36.892763Z",
     "shell.execute_reply.started": "2024-08-09T16:59:34.775393Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import asdict\n",
    "\n",
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import Index\n",
    "from sqlalchemy.orm import DeclarativeBase, Mapped, MappedAsDataclass, mapped_column\n",
    "\n",
    "\n",
    "# Define the models\n",
    "class Base(DeclarativeBase, MappedAsDataclass):\n",
    "    pass\n",
    "\n",
    "class Item(Base):\n",
    "    __tablename__ = \"items\"\n",
    "    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)\n",
    "    type: Mapped[str] = mapped_column()\n",
    "    brand: Mapped[str] = mapped_column()\n",
    "    name: Mapped[str] = mapped_column()\n",
    "    description: Mapped[str] = mapped_column()\n",
    "    price: Mapped[float] = mapped_column()\n",
    "    embedding: Mapped[Vector] = mapped_column(Vector(1536))  # ada-002\n",
    "\n",
    "    def to_dict(self, include_embedding: bool = False):\n",
    "        model_dict = asdict(self)\n",
    "        if include_embedding:\n",
    "            model_dict[\"embedding\"] = model_dict[\"embedding\"].tolist()\n",
    "        else:\n",
    "            del model_dict[\"embedding\"]\n",
    "        return model_dict\n",
    "\n",
    "    def to_str_for_rag(self):\n",
    "        return f\"Name:{self.name} Description:{self.description} Price:{self.price} Brand:{self.brand} Type:{self.type}\"\n",
    "\n",
    "    def to_str_for_embedding(self):\n",
    "        return f\"Name: {self.name} Description: {self.description} Type: {self.type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fd2fcfc-0f58-40cd-8190-399daa2d77b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:59:36.893777Z",
     "iopub.status.busy": "2024-08-09T16:59:36.893777Z",
     "iopub.status.idle": "2024-08-09T16:59:37.019613Z",
     "shell.execute_reply": "2024-08-09T16:59:37.019613Z",
     "shell.execute_reply.started": "2024-08-09T16:59:36.893777Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "from pgvector.utils import to_db\n",
    "from sqlalchemy import Float, Integer, column, select, text\n",
    "from sqlalchemy.ext.asyncio import AsyncSession\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "import json\n",
    "def extract_search_arguments(response_message: AIMessage):\n",
    "    search_query = None\n",
    "    filters = []\n",
    "    if response_message.tool_calls:\n",
    "        for tool in response_message.tool_calls:\n",
    "            if tool['type'] != \"tool_call\":\n",
    "                continue\n",
    "            if tool['name'] == \"search_database\":\n",
    "                arg = tool['args']\n",
    "                # Even though its required, search_query is not always specified\n",
    "                search_query = arg[\"search_query\"]\n",
    "                if \"price_filter\" in arg and arg[\"price_filter\"]:\n",
    "                    price_filter = arg[\"price_filter\"]\n",
    "                    filters.append(\n",
    "                        {\n",
    "                            \"column\": \"price\",\n",
    "                            \"comparison_operator\": price_filter[\"comparison_operator\"],\n",
    "                            \"value\": price_filter[\"value\"],\n",
    "                        }\n",
    "                    )\n",
    "                if \"brand_filter\" in arg and arg[\"brand_filter\"]:\n",
    "                    brand_filter = arg[\"brand_filter\"]\n",
    "                    filters.append(\n",
    "                        {\n",
    "                            \"column\": \"brand\",\n",
    "                            \"comparison_operator\": brand_filter[\"comparison_operator\"],\n",
    "                            \"value\": brand_filter[\"value\"],\n",
    "                        }\n",
    "                    )\n",
    "    elif query_text := response_message.content:\n",
    "        search_query = query_text.strip()\n",
    "    return search_query, filters\n",
    "\n",
    "\n",
    "class PostgresSearcher:\n",
    "    def __init__(\n",
    "        self,\n",
    "        db_session: AsyncSession,\n",
    "        aoai_embeddings: AzureOpenAIEmbeddings\n",
    "    ):\n",
    "        self.db_session = db_session\n",
    "        self.aoai_embeddings = aoai_embeddings\n",
    "\n",
    "    def build_filter_clause(self, filters) -> tuple[str, str]:\n",
    "        if filters is None:\n",
    "            return \"\", \"\"\n",
    "        filter_clauses = []\n",
    "        for filter in filters:\n",
    "            if isinstance(filter[\"value\"], str):\n",
    "                filter[\"value\"] = f\"'{filter['value']}'\"\n",
    "            filter_clauses.append(f\"{filter['column']} {filter['comparison_operator']} {filter['value']}\")\n",
    "        filter_clause = \" AND \".join(filter_clauses)\n",
    "        if len(filter_clause) > 0:\n",
    "            return f\"WHERE {filter_clause}\", f\"AND {filter_clause}\"\n",
    "        return \"\", \"\"\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query_text: str | None,\n",
    "        query_vector: list[float] | list,\n",
    "        top: int = 5,\n",
    "        filters: list[dict] | None = None,\n",
    "    ):\n",
    "        filter_clause_where, filter_clause_and = self.build_filter_clause(filters)\n",
    "\n",
    "        vector_query = f\"\"\"\n",
    "            SELECT id, RANK () OVER (ORDER BY embedding <=> :embedding) AS rank\n",
    "                FROM items\n",
    "                {filter_clause_where}\n",
    "                ORDER BY embedding <=> :embedding\n",
    "                LIMIT 20\n",
    "            \"\"\"\n",
    "\n",
    "        fulltext_query = f\"\"\"\n",
    "            SELECT id, RANK () OVER (ORDER BY ts_rank_cd(to_tsvector('english', description), query) DESC)\n",
    "                FROM items, plainto_tsquery('english', :query) query\n",
    "                WHERE to_tsvector('english', description) @@ query {filter_clause_and}\n",
    "                ORDER BY ts_rank_cd(to_tsvector('english', description), query) DESC\n",
    "                LIMIT 20\n",
    "            \"\"\"\n",
    "\n",
    "        hybrid_query = f\"\"\"\n",
    "        WITH vector_search AS (\n",
    "            {vector_query}\n",
    "        ),\n",
    "        fulltext_search AS (\n",
    "            {fulltext_query}\n",
    "        )\n",
    "        SELECT\n",
    "            COALESCE(vector_search.id, fulltext_search.id) AS id,\n",
    "            COALESCE(1.0 / (:k + vector_search.rank), 0.0) +\n",
    "            COALESCE(1.0 / (:k + fulltext_search.rank), 0.0) AS score\n",
    "        FROM vector_search\n",
    "        FULL OUTER JOIN fulltext_search ON vector_search.id = fulltext_search.id\n",
    "        ORDER BY score DESC\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "\n",
    "        if query_text is not None and len(query_vector) > 0:\n",
    "            sql = text(hybrid_query).columns(column(\"id\", Integer), column(\"score\", Float))\n",
    "        elif len(query_vector) > 0:\n",
    "            sql = text(vector_query).columns(column(\"id\", Integer), column(\"rank\", Integer))\n",
    "        elif query_text is not None:\n",
    "            sql = text(fulltext_query).columns(column(\"id\", Integer), column(\"rank\", Integer))\n",
    "        else:\n",
    "            raise ValueError(\"Both query text and query vector are empty\")\n",
    "\n",
    "        results = (\n",
    "            self.db_session.execute(\n",
    "                sql,\n",
    "                {\"embedding\": to_db(query_vector), \"query\": query_text, \"k\": 60},\n",
    "            )\n",
    "        ).fetchall()\n",
    "\n",
    "        # Convert results to Item models\n",
    "        items = []\n",
    "        for id, _ in results[:top]:\n",
    "            item = self.db_session.execute(select(Item).where(Item.id == id))\n",
    "            items.append(item.scalar())\n",
    "        return items\n",
    "\n",
    "    def search_and_embed(\n",
    "        self,\n",
    "        query_text: str | None = None,\n",
    "        top: int = 5,\n",
    "        enable_vector_search: bool = True,\n",
    "        enable_text_search: bool = True,\n",
    "        filters: list[dict] | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Search items by query text. Optionally converts the query text to a vector if enable_vector_search is True.\n",
    "        \"\"\"\n",
    "        vector: list[float] = []\n",
    "        if enable_vector_search and query_text is not None:\n",
    "            vector = self.aoai_embeddings.embed_query(query_text)\n",
    "        if not enable_text_search:\n",
    "            query_text = None\n",
    "        return self.search(query_text, vector, top, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "301d9582-6f45-4ef3-af8b-b6ef3694299b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:59:37.501025Z",
     "iopub.status.busy": "2024-08-09T16:59:37.501025Z",
     "iopub.status.idle": "2024-08-09T16:59:38.091471Z",
     "shell.execute_reply": "2024-08-09T16:59:38.087793Z",
     "shell.execute_reply.started": "2024-08-09T16:59:37.501025Z"
    }
   },
   "outputs": [],
   "source": [
    "from pgvector.utils import to_db\n",
    "from sqlalchemy import Float, Integer, column, select, text\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "engine = create_engine(os.environ['POSTGRES_CONNECTION_STRING'])\n",
    "database_session = sessionmaker(\n",
    "        engine,\n",
    "        expire_on_commit=False,\n",
    "        autoflush=False,\n",
    "    )\n",
    "\n",
    "searcher = PostgresSearcher(\n",
    "        db_session=database_session(),\n",
    "        aoai_embeddings = aoai_embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3823e4-0f0b-4cd3-adf5-7aa415499f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:59:39.870876Z",
     "iopub.status.busy": "2024-08-09T16:59:39.867851Z",
     "iopub.status.idle": "2024-08-09T16:59:54.255525Z",
     "shell.execute_reply": "2024-08-09T16:59:54.250540Z",
     "shell.execute_reply.started": "2024-08-09T16:59:39.870876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "tool_call[\"args\"] {'search_query': 'climbing gear outside'}\n",
      "**************************\n",
      "**************************\n",
      "tool_call[\"args\"] {'search_query': 'shoes', 'price_filter': {'comparison_operator': '<', 'value': 50}}\n",
      "**************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 19, 'type': 'Footwear', 'brand': 'Green Equipment', 'name': 'EcoTrail Running Shoes', 'description': 'Experience the great outdoors while reducing your carbon footprint with the Green Equipment EcoTrail Running Shoes. Made from recycled materials, these shoes offer a lightweight, breathable, and flexible design in an earthy green color. With their durable Vibram outsole and cushioned midsole, they provide optimal comfort and grip on any trail.', 'price': 119.99}, page_content='Name:EcoTrail Running Shoes Description:Experience the great outdoors while reducing your carbon footprint with the Green Equipment EcoTrail Running Shoes. Made from recycled materials, these shoes offer a lightweight, breathable, and flexible design in an earthy green color. With their durable Vibram outsole and cushioned midsole, they provide optimal comfort and grip on any trail. Price:119.99 Brand:Green Equipment Type:Footwear'),\n",
       " Document(metadata={'id': 11, 'type': 'Climbing', 'brand': 'WildRunner', 'name': 'Vertical Journey Climbing Shoes', 'description': 'The Vertical Journey Climbing Shoes from WildRunner in sleek black are the perfect companion for any climbing enthusiast. With an aggressive down-turned toe, sticky rubber outsole, and reinforced heel cup for added support, these shoes offer ultimate performance on even the most challenging routes.', 'price': 129.99}, page_content='Name:Vertical Journey Climbing Shoes Description:The Vertical Journey Climbing Shoes from WildRunner in sleek black are the perfect companion for any climbing enthusiast. With an aggressive down-turned toe, sticky rubber outsole, and reinforced heel cup for added support, these shoes offer ultimate performance on even the most challenging routes. Price:129.99 Brand:WildRunner Type:Climbing'),\n",
       " Document(metadata={'id': 40, 'type': 'Footwear', 'brand': 'Green Equipment', 'name': 'EcoTrek Trail Running Shoes', 'description': 'Hit the trails with the EcoTrek Trail Running Shoes by Green Equipment. Designed with eco-friendly materials, these shoes feature a comfortable fit, responsive cushioning, and a durable outsole for optimal grip on rugged terrains. The forest green color is inspired by nature and adds a refreshing touch to your outdoor look.', 'price': 99.99}, page_content='Name:EcoTrek Trail Running Shoes Description:Hit the trails with the EcoTrek Trail Running Shoes by Green Equipment. Designed with eco-friendly materials, these shoes feature a comfortable fit, responsive cushioning, and a durable outsole for optimal grip on rugged terrains. The forest green color is inspired by nature and adds a refreshing touch to your outdoor look. Price:99.99 Brand:Green Equipment Type:Footwear')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_community.adapters.openai import convert_openai_messages\n",
    "\n",
    "system_prompt = \"\"\"Below is a history of the conversation so far, and a new question asked by the user that needs to be answered by searching database rows.\n",
    "You have access to an Azure PostgreSQL database with an items table that has columns for title, description, brand, price, and type.\n",
    "Generate a search query based on the conversation and the new question.\n",
    "If the question is not in English, translate the question to English before generating the search query.\n",
    "If you cannot generate a search query, return the original user question.\n",
    "DO NOT return anything besides the query.\"\"\"\n",
    "\n",
    "class ToyRetriever(BaseRetriever):\n",
    "    \"\"\"List of documents to retrieve from.\"\"\"\n",
    "    k: int\n",
    "    \"\"\"Number of top results to return\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Sync implementations for retriever.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"few_shot_examples\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ])\n",
    "        context_retriever_chain = prompt | llm \n",
    "        response_message = context_retriever_chain.invoke({\"input\": query,\n",
    "                                                           \"few_shot_examples\": convert_openai_messages(few_shot_messages), \n",
    "                                                           \"chat_history\":[]})\n",
    "        query_text, filters = extract_search_arguments(response_message)\n",
    "        results = searcher.search_and_embed(\n",
    "                query_text,\n",
    "                top=3,\n",
    "                enable_vector_search=True,\n",
    "                enable_text_search=True,\n",
    "                filters=filters,\n",
    "            )\n",
    "        sources_content = [f\"[{(item.id)}]:{item.to_str_for_rag()}\\n\\n\" for item in results]\n",
    "        matching_documents = []\n",
    "        for item in results:\n",
    "            if len(matching_documents) > self.k:\n",
    "                return matching_documents\n",
    "            matching_documents.append(Document(page_content = item.to_str_for_rag(), metadata = item.to_dict()))\n",
    "        return matching_documents\n",
    "\n",
    "retriever = ToyRetriever(k = 3)\n",
    "retriever.invoke(\"that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4161915-372a-47a6-a873-13a25cc9dbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T17:03:01.633915Z",
     "iopub.status.busy": "2024-08-09T17:03:01.633915Z",
     "iopub.status.idle": "2024-08-09T17:03:11.870359Z",
     "shell.execute_reply": "2024-08-09T17:03:11.870359Z",
     "shell.execute_reply.started": "2024-08-09T17:03:01.633915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "tool_call[\"args\"] {'search_query': 'climbing gear outside'}\n",
      "**************************\n",
      "**************************\n",
      "tool_call[\"args\"] {'search_query': 'shoes', 'price_filter': {'comparison_operator': '<', 'value': 50}}\n",
      "**************************\n",
      "Here are some good options for climbing gear under $90:\n",
      "\n",
      "1. **Apex Climbing Harness by Legend**: This harness offers a secure fit with adjustable leg loops, a contoured waistbelt, and a secure buckle system. It's priced at $89.99 [ID: Apex Climbing Harness].\n",
      "\n",
      "2. **Guardian Blue Chalk Bag by Legend**: This durable chalk bag features a spacious compartment, a drawstring closure, and a waist belt for easy access while climbing. It's priced at $21.99 [ID: Guardian Blue Chalk Bag].\n",
      "\n",
      "3. **Summit Pro Harness by Gravitator**: This harness provides a customized fit with adjustable leg loops and waist belt. Safety features include a reinforced tie-in point and strong webbing loops. It's priced at $89.99 [ID: Summit Pro Harness].\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, PromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"Assistant helps customers with questions about products.\n",
    "Respond as if you are a salesperson helping a customer in a store. Do NOT respond with tables.\n",
    "Answer ONLY with the product details listed in the products.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Each product has an ID in brackets followed by colon and the product details.\n",
    "Always include the product ID for each product you use in the response.\n",
    "Use square brackets to reference the source, for example [52].\n",
    "Don't combine citations, list each product separately, for example [27][51].\"\"\"\n",
    "\n",
    "\n",
    "# Create the final prompt template\n",
    "final_prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=system_prompt)),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate(prompt=PromptTemplate(\n",
    "            input_variables=['context','input'], \n",
    "            template=\"Question: {input} \\nContext: {context} \\nAnswer:\"\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \n",
    "     \"input\": RunnablePassthrough(),\n",
    "     \"chat_history\": RunnableLambda(lambda x: x.get(\"chat_history\", []))}\n",
    "    | final_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "response = rag_chain.invoke({\n",
    "        \"input\": \"good options for climbing gear anything less than 90$?\",\n",
    "        \"chat_history\": []\n",
    "    })\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52f9c4-0703-4eb7-9d1b-cefa03657387",
   "metadata": {
    "execution": {
     "execution_failed": "2024-08-09T16:56:46.669Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "qa_system_prompt = \"\"\"Assistant helps customers with questions about products.\n",
    "Respond as if you are a salesperson helping a customer in a store. Do NOT respond with tables.\n",
    "Answer ONLY with the product details listed in the products.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Each product has an ID in brackets followed by colon and the product details.\n",
    "Always include the product ID for each product you use in the response.\n",
    "Use square brackets to reference the source, for example [52].\n",
    "Don't combine citations, list each product separately, for example [27][51].\\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = RunnableBranch(\n",
    "        (\n",
    "            # Both empty string and empty list evaluate to False\n",
    "            lambda x: not x.get(\"chat_history\", False),\n",
    "            # If no chat history, then we just pass input to retriever\n",
    "            (lambda x: x[\"input\"]) | retriever,\n",
    "        ),\n",
    "        # If chat history, then we pass inputs to LLM chain, then to retriever\n",
    "        contextualize_q_prompt | llm | StrOutputParser() | retriever\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    print(\"****************************************\")\n",
    "    print(docs)\n",
    "    print(\"****************************************\")\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "retrieval_chain = RunnablePassthrough.assign(context= (lambda x: x[\"input\"]) | retriever | format_docs).assign(answer=question_answer_chain)\n",
    "\n",
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    retrieval_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")\n",
    "response = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"good options for climbing shoes anything less than 90$?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718c71b-2fbb-4019-a81a-5aee5000f901",
   "metadata": {
    "execution": {
     "execution_failed": "2024-08-09T16:56:46.669Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, PromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"Assistant helps customers with questions about products.\n",
    "Respond as if you are a salesperson helping a customer in a store. Do NOT respond with tables.\n",
    "Answer ONLY with the product details listed in the products.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the sources below.\n",
    "Each product has an ID in brackets followed by colon and the product details.\n",
    "Always include the product ID for each product you use in the response.\n",
    "Use square brackets to reference the source, for example [52].\n",
    "Don't combine citations, list each product separately, for example [27][51].\"\"\"\n",
    "\n",
    "\n",
    "# Create the final prompt template\n",
    "final_prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=system_prompt)),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate(prompt=PromptTemplate(\n",
    "            input_variables=['context','input'], \n",
    "            template=\"Question: {input} \\nContext: {context} \\nAnswer:\"\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def search_function(response_message):\n",
    "    query_text, filters = extract_search_arguments(response_message)\n",
    "    print(\"query_text\", query_text)\n",
    "    print(\"filters\", filters)\n",
    "    results = searcher.search_and_embed(\n",
    "                query_text,\n",
    "                top=3,\n",
    "                enable_vector_search=True,\n",
    "                enable_text_search=True,\n",
    "                filters=filters,\n",
    "            )\n",
    "    sources_content = [f\"[{(item.id)}]:{item.to_str_for_rag()}\\n\\n\" for item in results]\n",
    "    content = \"\\n\".join(sources_content)\n",
    "    return content\n",
    "\n",
    "# Combine everything into a single chain\n",
    "combined_chain = (\n",
    "    {\n",
    "        \"input\": RunnablePassthrough(),\n",
    "        \"response_message\": context_retriever_chain,\n",
    "        \"chat_history\": RunnablePassthrough()\n",
    "    }\n",
    "    | final_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "combined_chain = (\n",
    "    {\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "        \"context\" : context_retriever_chain | search_function\n",
    "    }\n",
    "    | final_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Usage\n",
    "def run_combined_chain(input_question, few_shot_examples, chat_history):\n",
    "    return combined_chain.invoke({\n",
    "        \"input\": input_question,\n",
    "        \"few_shot_examples\": convert_openai_messages(few_shot_examples),\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "\n",
    "# Example usage\n",
    "result = run_combined_chain(\n",
    "    input_question = \"good options for climbing gear anything less than 90$?\",\n",
    "    few_shot_examples = few_shot_messages,\n",
    "    chat_history = []\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca699f3-b986-4a42-89c6-3f850b5de491",
   "metadata": {
    "execution": {
     "execution_failed": "2024-08-09T16:56:46.670Z"
    }
   },
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063faf5-e8f3-4bcf-8931-8362ba4ebcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
