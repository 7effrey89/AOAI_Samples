{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f76db8",
   "metadata": {},
   "source": [
    "# Index and Summarize Advertising Video Creatives with Azure Open AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e6ddd",
   "metadata": {},
   "source": [
    "## Process:\n",
    "\n",
    "1. Data Preparation\n",
    "2. Ingest Videos to a **Video Index**\n",
    "3. Summarize Videos with **GPT4-Turbo with Vision**\n",
    "\n",
    "## Documentation:\n",
    "\n",
    "- [Azure AI Vision Documentation](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/)\n",
    "- [GPT-4 Turbo with Vision + Azure AI Vision](https://techcommunity.microsoft.com/t5/microsoft-mechanics-blog/gpt-4-turbo-with-vision-azure-ai-vision/ba-p/4009630)\n",
    "- [Azure AI OpenAI Documentation](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview)\n",
    "- [Quickstart Tutorial: GPT4-Turbo with Vision](https://learn.microsoft.com/en-us/azure/ai-services/openai/gpt-v-quickstart?tabs=image&pivots=rest-api)\n",
    "- [Use Vision enhancement with video](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/gpt-with-vision#use-vision-enhancement-with-video)\n",
    "- [Video Retrieval Integrated with GPT4-Turbo with Vision](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/video-retrieval-gpt-4-turbo-with-vision-integrates-with-azure-to/ba-p/3982753)\n",
    "- [GPT4-Turbo with Vision](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/gpt-4-turbo-with-vision-on-azure-openai-service/ba-p/3979933)\n",
    "- [GPT-4 Turbo with Vision is now available on Azure OpenAI Service!](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/gpt-4-turbo-with-vision-is-now-available-on-azure-openai-service/ba-p/4008456)\n",
    "- [Video Retrieval API - Florence](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/video-retrieval)\n",
    "- [Video Retrieval API - Reference](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/reference-video-search)\n",
    "\n",
    "## Related Videos:\n",
    "\n",
    "- [GPT-4 Turbo with Vision + Azure AI Vision](https://www.youtube.com/watch?v=KPTVu-AeG7g)\n",
    "- [Multimodal Conversational Interfaces with GPT and Vision AI](https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fignite.microsoft.com%2Fen-US%2Fsessions%2F02b1a86c-657f-41e2-ac05-226e1a83f771&data=05%7C01%7Cmariamchahin%40microsoft.com%7C560e1a4b2fba4dbc2a7608dbe9db1cc1%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638360899542768074%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=05sQnTnuM9xWDxwOcUjCDo%2B6uGHZmUABRp4s9InW2NQ%3D&reserved=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c8753",
   "metadata": {
    "gather": {
     "logged": 1699868565590
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade -r requirements.txt\n",
    "#https://mwouts.github.io/itables/quick_start.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f6185",
   "metadata": {
    "gather": {
     "logged": 1699869588482
    }
   },
   "outputs": [],
   "source": [
    "import project_path\n",
    "from src import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1024)\n",
    "pd.set_option(\"expand_frame_repr\", False)\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Image\n",
    "from IPython.display import Video\n",
    "from IPython.display import Audio\n",
    "from azureml.core import Workspace, Dataset\n",
    "from itables import init_notebook_mode, show\n",
    "import itables.options as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27930e37",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Pytube python library:  \n",
    "https://pytube.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74a98a-30bb-4310-8a05-544e6c6ba4c5",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1699869611116
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "## Download Advertising Videos form Youtube:\n",
    "video_df = utils.download_youtube_videos()\n",
    "\n",
    "video_df[\"ADNAME\"]=video_df[\"id\"]+\".mp4\"\n",
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833831cf",
   "metadata": {},
   "source": [
    "## 2. Ingest Videos to a Video Index\n",
    "\n",
    "\n",
    "<p align=\"left\">\n",
    "  <img width=\"750\" src=\"..\\images\\VideoSearch.png\" />\n",
    "</p>\n",
    "\n",
    "Video Retrieval API Docs:\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/video-retrieval\n",
    "\n",
    "https://github.com/Azure/Media-Retrieval/blob/main/VideoRetrieval.md\n",
    "\n",
    "\n",
    "Video Retrieval enables GPT-4 Turbo with Vision to answer video prompts using a curated set of images from the video as grounding data. This means that when you ask specific questions about scenes, objects or events in a video, the system provides more accurate answers without sending all the frames to the large multimodal model (LMM). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce3a90",
   "metadata": {},
   "source": [
    "### 2.1: Create an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607611ce",
   "metadata": {
    "gather": {
     "logged": 1699863742307
    }
   },
   "outputs": [],
   "source": [
    "#Step 1.2: (Optional) Delete the Video Index\n",
    "AZURE_CV_API_VERSION = os.getenv(\"AZURE_CV_API_VERSION\")\n",
    "\n",
    "url = AZURE_CV_ENDPOINT +\\\n",
    "\"/computervision/retrieval/indexes/\"+VIDEO_INDEX+\"?api-version=\"+AZURE_CV_API_VERSION\n",
    "utils.json_http_request(url,\n",
    "body=None,\n",
    "headers= {\n",
    "    'Ocp-Apim-Subscription-Key': AZURE_CV_KEY,\n",
    "}, \n",
    "type=\"DELETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c14ff",
   "metadata": {
    "gather": {
     "logged": 1699863750021
    }
   },
   "outputs": [],
   "source": [
    "#Step 1.1: Create the Video Index\n",
    "url = AZURE_CV_ENDPOINT +\\\n",
    "\"/computervision/retrieval/indexes/\"+VIDEO_INDEX+\"?api-version=\"+os.getenv(\"AZURE_CV_API_VERSION\")\n",
    "headers = {\n",
    "    'Content-type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': AZURE_CV_KEY,\n",
    "}\n",
    "\n",
    "body = {\n",
    "  \"metadataSchema\": {\n",
    "    \"language\": \"en\",\n",
    "    \"fields\": [\n",
    "      {\n",
    "        \"name\": \"ADNAME\",\n",
    "        \"searchable\": False,\n",
    "        \"filterable\": True,\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"title\",\n",
    "        \"searchable\": True,\n",
    "        \"filterable\": False,\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"description\",\n",
    "        \"searchable\": True,\n",
    "        \"filterable\": False,\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"author\",\n",
    "        \"searchable\": True,\n",
    "        \"filterable\": True,\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      {\n",
    "        'name': 'publish_date',\n",
    "        'searchable': False,\n",
    "        'filterable': True,\n",
    "        'type': 'datetime'\n",
    "      },\n",
    "      {\n",
    "        'name': 'length',\n",
    "        'searchable': False,\n",
    "        'filterable': True,\n",
    "        'type': 'string'\n",
    "      },\n",
    "      {\n",
    "        'name': 'views',\n",
    "        'searchable': False,\n",
    "        'filterable': True,\n",
    "        'type': 'string'\n",
    "      },\n",
    "      {\n",
    "        'name': 'keywords',\n",
    "        'searchable': True,\n",
    "        'filterable': False,\n",
    "        'type': 'string'\n",
    "      }\n",
    "\n",
    "    ]\n",
    "  },\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"name\": \"vision\",\n",
    "      \"domain\": \"generic\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"speech\",\n",
    "      \"domain\": \"generic\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "r = requests.put(url, json=body, headers=headers)\n",
    "result=r.json()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982b350",
   "metadata": {},
   "source": [
    "### 2.2: Add Video Files to the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f81da-ca1e-4112-9f18-ce52c47a55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/reference-video-search#createingestionrequestmodel\n",
    "\n",
    "import base64\n",
    "\n",
    "INGESTION_NAME=VIDEO_INDEX+\"-ingestion\"\n",
    "url = AZURE_CV_ENDPOINT +\\\n",
    "\"/computervision/retrieval/indexes/\"+VIDEO_INDEX+\"/ingestions/\"+INGESTION_NAME+\"?api-version=\"+os.getenv(\"AZURE_CV_API_VERSION\")\n",
    "video_df[\"publish_date\"]=video_df[\"publish_date\"].astype(str).tolist()\n",
    "videos_dict = video_df.T.to_dict()\n",
    "\n",
    "videos= list(\n",
    "  map(lambda x:  {\n",
    "      \"mode\": \"add\",\n",
    "      \"documentId\": x[1][\"id\"],\n",
    "      \"documentUrl\": x[1]['document_url'],\n",
    "      \"metadata\": {\n",
    "        \"ADNAME\": x[1][\"ADNAME\"],\n",
    "        \"publish_date\": x[1][\"publish_date\"],\n",
    "        \"length\": str(x[1][\"length\"]),\n",
    "        \"views\": str(x[1][\"views\"]),\n",
    "        \"title\": x[1][\"title\"],\n",
    "        \"description\": x[1][\"description\"],\n",
    "        \"keywords\": \",\".join(x[1][\"keywords\"]),\n",
    "        \"author\": x[1][\"author\"]\n",
    "      }\n",
    "    },\n",
    "    list(videos_dict.items())\n",
    "  )\n",
    ")\n",
    "\n",
    "body = {\n",
    "  \"videos\": videos,\n",
    "  \"includeSpeechTranscrpt\": True,\n",
    "  \"moderation\": False\n",
    "}\n",
    "\n",
    "r = requests.put(url, json=body, headers=headers)\n",
    "result=r.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b155a34",
   "metadata": {},
   "source": [
    "### Step 2.3: Wait for the Ingestion to Completed\n",
    "\n",
    "Wait until the indexing turns from **Running** to **Completed** state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea26c40",
   "metadata": {
    "gather": {
     "logged": 1699863987063
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get(AZURE_CV_ENDPOINT +'/computervision/retrieval/indexes/'+VIDEO_INDEX+'/ingestions?api-version='+os.getenv(\"AZURE_CV_API_VERSION\")+'&$top=20', \n",
    "headers= {\n",
    "    'Ocp-Apim-Subscription-Key': AZURE_CV_KEY,\n",
    "})\n",
    "\n",
    "print(\"IndexingState: \" + r.json()[\"value\"][0][\"state\"])\n",
    "\n",
    "if r.json()[\"value\"][0][\"state\"]!=\"Completed\" and r.json()[\"value\"][0][\"state\"]!=\"PartiallySucceeded\":\n",
    "    print(r.json())\n",
    "else:\n",
    "    r = requests.get(AZURE_CV_ENDPOINT +'/computervision/retrieval/indexes/'+VIDEO_INDEX+'/documents?api-version='+os.getenv(\"AZURE_CV_API_VERSION\")+'&$top=5', \n",
    "    headers= {\n",
    "        'Ocp-Apim-Subscription-Key': AZURE_CV_KEY,\n",
    "    })\n",
    "    print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb401533",
   "metadata": {},
   "source": [
    "### Step 2.4: Read All Documents in Video Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read All Advertising Documents in Video Index\n",
    "indexed_videos_df = utils.get_indexed_video_documents()\n",
    "\n",
    "indexed_videos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97cfaa",
   "metadata": {},
   "source": [
    "### Step 2.5: Perform Searches with Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd9af5",
   "metadata": {
    "gather": {
     "logged": 1699863999518
    }
   },
   "outputs": [],
   "source": [
    "adname='AYU4q594LJ0.mp4'\n",
    "\n",
    "search_results=utils.search_text_by_adname(\n",
    "    queryText=\"microsoft icon\",\n",
    "    adname=adname,\n",
    "    featureFilters=[\"vision\"]\n",
    "    )['value']\n",
    "\n",
    "pd.DataFrame.from_records(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f10709-4c84-43a6-887f-f1c3b91f2686",
   "metadata": {},
   "source": [
    "# 3. Summarize Videos with GPT4-Turbo with Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b85163",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_videos_df= indexed_videos_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45dfc4-f098-4e91-9c4e-555354319629",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1699869810459
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Creating a short summary\n",
    "def compose_prompt_v1():\n",
    "    return \"Describe the advertising video\"\n",
    "\n",
    "## Calls GPT4V for each element of the dataframe\n",
    "indexed_videos_df[\"GPT4V_SUMMARY_V1\"]=indexed_videos_df.apply(lambda row:utils.call_OpenAI_ChatCompletions_GPT4Video_API(\n",
    "    document_id=row[\"documentId\"],\n",
    "    video_url=row[\"documentUrl\"]+SAS_TOKEN,\n",
    "    prompt=compose_prompt_v1(),\n",
    "    temperature=0.7, \n",
    "    max_tokens=300, \n",
    "    top_p= 0.95\n",
    ").get('assistant_response', \"\"),axis=1)\n",
    "\n",
    "utils.pretty_print(indexed_videos_df[[\"adname\",\"GPT4V_SUMMARY_V1\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909203b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_detailed_script_prompt():\n",
    "    return \"\"\"Create a script for talking and reacting on the top of this advertising creative video. \n",
    "Respond with a valid .srt file format for the comments and timings.\"\"\"\n",
    "\n",
    "## Calls GPT4V for each element of the dataframe\n",
    "indexed_videos_df[\"GPT4V_DETAILED_SCRIPT\"]=indexed_videos_df.apply(lambda row:utils.call_OpenAI_ChatCompletions_GPT4Video_API(\n",
    "    document_id=row[\"documentId\"],\n",
    "    video_url=row[\"documentUrl\"]+SAS_TOKEN,\n",
    "    prompt=compose_detailed_script_prompt(),\n",
    "    temperature=0.7, \n",
    "    max_tokens=1000, \n",
    "    top_p= 0.95\n",
    ").get('assistant_response', \"\"),axis=1)\n",
    "\n",
    "\n",
    "utils.pretty_print(indexed_videos_df[[\"adname\",\"GPT4V_DETAILED_SCRIPT\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e1334-2b68-40ef-9991-8c2772fbe497",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def compose_system_message(row):\n",
    "    return f\"\"\"\n",
    "    Your task is to assist in analyzing and optimizing creative assets.\n",
    "    You will be presented with images and transcript from the advertisement video.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def compose_prompt_v2(row):\n",
    "    return \"\"\"First describe the video in detail paying close attention to Product characteristics highlighted, \n",
    "    Background images, Lighting, Color Palette and Human characteristics for persons in the video. \n",
    "    Explicitly mention the product brand or logo. Finally provide a summary of the video \n",
    "    and talk about the main message the advertisement video tries to convey to the viewer.\"\"\"\n",
    "\n",
    "## Calls GPT4V for each element of the dataframe\n",
    "indexed_videos_df[\"GPT4V_SUMMARY_V2\"]=indexed_videos_df.apply(lambda row:utils.call_OpenAI_ChatCompletions_GPT4Video_API(\n",
    "    document_id=row[\"documentId\"],\n",
    "    video_url=row[\"documentUrl\"]+SAS_TOKEN,\n",
    "    prompt=compose_prompt_v2(row),\n",
    "    system_message=compose_system_message(row),\n",
    "    temperature=0.7, \n",
    "    max_tokens=500, \n",
    "    top_p= 0.95\n",
    ").get('assistant_response', \"\"),axis=1)\n",
    "\n",
    "\n",
    "utils.pretty_print(indexed_videos_df[[\"adname\",\"GPT4V_SUMMARY_V2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795affb-1ff1-43bc-9a16-0d137b78f527",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1699869553608
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "indexed_videos_df[\"AD_VIDEO\"] = indexed_videos_df.apply(lambda row:utils.get_video_html_tag(os.path.join(VIDEO_DIR,row[\"adname\"])), axis=1)\n",
    "indexed_videos_df.index=indexed_videos_df[\"adname\"]\n",
    "\n",
    "del indexed_videos_df[\"adname\"]\n",
    "\n",
    "cols = list(indexed_videos_df.columns)\n",
    "\n",
    "a, b = cols.index('AD_VIDEO'), cols.index('documentId')\n",
    "cols[a],cols[b] = cols[b],cols[a]\n",
    "digital_df = indexed_videos_df[cols]\n",
    "\n",
    "transposed_df=digital_df.T\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "#show(indexed_videos_df, classes=\"display wrap compact\", column_filters=\"footer\", dom=\"lrtip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e652ef-1000-4026-a102-c27fbfb6cfe2",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1699869503790
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ADNAME=\"AYU4q594LJ0.mp4\"\n",
    "show(transposed_df[[ADNAME]], classes=\"display wrap compact\", paging=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to a Parquet File\n",
    "del indexed_videos_df[\"userData\"]\n",
    "indexed_videos_df.to_parquet(REF_DIR+\"/summarized_youtube.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
